\documentclass[11pt,mathserif]{beamer}

%% paketeak
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{svg}
\usepackage{graphicx}
\usepackage{bbding}
\usepackage{fontawesome}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{fancyvrb}
\usepackage{relsize}
\usepackage{color}
\usepackage{listings}
\usepackage{caption}
\usepackage{bbold}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage[absolute,overlay]{textpos}
\usepackage{ifthen}
% kolore batzuk definitu
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{bleuSympa}{rgb}{0.,0.19,0.607}
\definecolor{arrosa}{rgb}{0.7,0.15,0.15}
\definecolor{testcolor}{rgb}{0.8,0,0.9}
\definecolor{moncyan}{rgb}{0.01,0.89,1}

% eskol-zaharreko estiloa 
\setbeamercolor{frametitle}{fg=green}
\setbeamercolor{background canvas}{bg=black}
\setbeamercolor{normal text}{fg=green}
\setbeamercolor*{structure}{bg=black,fg=yellow}


% bidexka erabilgarriak fontawesome erabiltzen
\renewcommand{\thefootnote}{$\dagger$}
\newcommand{\scout}{\faAngellist}
\newcommand{\gezi}{\faLongArrowRight}
\newcommand{\galde}{\faQuestion}
\newcommand{\bof}{\faMehRollingEyes[regular]}
\newcommand{\hand}{\faHandORight}
\newcommand{\argi}{\faLightbulbO}
\newcommand{\Pdf}{\faFilePdfO}
\newcommand{\liburu}{\faBook}
\newcommand{\kontuz}{\faExclamationTriangle}
\newcommand{\pozik}{\faSmileO}
\newcommand{\triste}{\faFrownO}
\newcommand{\egia}{\faCheckCircle}
\newcommand{\adibi}{\faCommentO}
\newcommand{\harritu}{\faExclamation}
\newcommand{\geldi}{\faHandPaperO}
\captionsetup[figure]{labelformat=empty}
\newcommand{\geziBikoitz}{\faArrowsH}

% c/fortran aukeratzeko
\newif\ifC
\ifthenelse{\equal{\detokenize{c}}{\jobname}}{
  \Ctrue
}{
  \Cfalse
}
\ifC
  \newcommand{\mylang}{c}
  \newcommand{\othlang}{fortran}
  \newcommand{\extlang}{c}
  \newcommand{\extcu}{cu}
  \newcommand{\spt}{.}
\else
  \newcommand{\mylang}{fortran}
  \newcommand{\othlang}{c}
  \newcommand{\extlang}{f90}
  \newcommand{\extcu}{cuf}
  \newcommand{\spt}{\%}
\fi
\newcommand{\includeSrc}[1]{\lstinputlisting[language=\mylang]{#1.\extlang}}
\newcommand{\includeSrcCu}[1]{\lstinputlisting{#1.\extcu}}

% listings CUDA lengoaia kudeatzeko
\lstset{ %
  numbers=left,
  numbersep=1pt,
  numberstyle=\relsize{-5}\ttfamily,
  language=\mylang,                % the language of the code
  framerule=1pt,
  basicstyle=\relsize{-3}\ttfamily,           % the size of the fonts that are used for the code
                                  % will be numbered
  %numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{black},      % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  %frame=single,                   % adds a frame around the code
  rulecolor=\color{white},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  %tabsize=2,                      % sets default tabsize to 2 spaces
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  lineskip=-1pt,
%\ifC
  emph={__global__, __shared__, __device__, __host__, __syncthreads, threadIdx, blockIdx, blockDim, gridDim, warpSize},
%\else
%  emph={global, shared, device, host, syncthreads, attributes, threadIdx, blockIdx, blockDim, gridDim},
%\fi
  keywordstyle=\color{yellow}\textbf,          % keyword style
  commentstyle=\color{moncyan},       % comment style
  stringstyle=\color{mauve},
  emphstyle=\color{testcolor},
  moredelim=[s][\color{arrosa}\ttfamily]{<<<}{>>>},
  morecomment=[s][\color{mauve}]{cudaMemcpyHostToDevice}{\ },
  morecomment=[s][\color{mauve}]{cudaMemcpyDeviceToHost}{\ }
}

%% ====== nire beamer estiloa
\defbeamertemplate{itemize item}{boldarrow}{\raisebox{0.3ex}{\resizebox{1.2ex}{1ex}{\ArrowBoldRightShort}}}
\mode<presentation> {
\usetheme{default}    % urri
\useinnertheme[shadow]{rounded}  % zenbakiak biribiltzeko
}
\usefonttheme{structurebold}

\begin{document}

%****************************************************************
% Aurkezpen orria
%**************************************************************
\begin{frame}
\begin{center}
  {\Large Introduction au calcul sur GPU }
\end{center}
\begin{center}
\includegraphics[width=0.5\linewidth]{fig/gpu.jpg}
\end{center}
 \begin{center}
{\large Marc Fuentes - INRIA Pau\\ }
\end{center}
\end{frame}

%****************************************************************
% Xedea
%**************************************************************
\begin{frame}{Plan}
\begin{itemize}[<+->]
   \item Découverte
     \begin{itemize}
       \item Exemples d'applications 
       \item Prolégomènes (parallèlisme, mémoire, cache)
       \item Exemple d'introduction
       \item Modèle d'exécution d'un GPU
       \item Accès mémoires et coalescence
       \item Outils (déverminage, profilage)
     \end{itemize}
 \item Optimisation 
     \begin{itemize}
       \item Facteurs limitants (mémoire, instructions, latence)
       \item Métriques (BP, occupation)
       \item Transferts hôte \geziBikoitz\ accélérateur
       \item Mémoires de l'accélérateur
       \item Divergence de threads \& réductions
     \end{itemize}
  \item Divers
     \begin{itemize}
       \item Une brève histoire des GPUs
       \item Interfaces de programmation applicatives (IPA)
     \end{itemize}
\end{itemize}
\end{frame}

%****************************************************************
% lehen kapitulua
%****************************************************************
\begin{frame}
  \begin{center}
    {\Huge Première partie : Découverte}
  \end{center}
\end{frame}

%****************************************************************
% erabilpenak
%**************************************************************
% neurona-sare marrazteko
\begin{frame}[fragile]{Utilisation des GPU}
\pause
  \begin{itemize}[<+->]
    \item[\adibi]
      \begin{minipage}[c]{0.49\linewidth}
        calcul haute performance (HPC) : simulation numérique de grande taille
      \end{minipage}
      \begin{minipage}[c]{0.49\linewidth}
        \begin{figure}
         \includegraphics[width=0.6\linewidth]{fig/titan.jpg}
          \caption{\tiny Supercalculateur Titan : $\thicksim$ 18000 GPU}
        \end{figure}
      \end{minipage}
    \item[\adibi]  \begin{minipage}[l]{0.49\linewidth}
     traitement d'image, jeux vidéos 
      \end{minipage}
      \begin{minipage}[r]{0.49\linewidth}
        \begin{figure}
        \includegraphics[width=0.6\linewidth]{fig/minetest.jpg}
          \caption{\tiny Minetest}
        \end{figure}
      \end{minipage}
    \item[\adibi]  \begin{minipage}[l]{0.49\linewidth}
     apprentissage automatique
      \end{minipage}
      \begin{minipage}[l]{0.49\linewidth}
        \newcommand{\sarrera}{3} 
        \newcommand{\ezkututa}{5}  
        \newcommand{\irteera}{2} 
        \begin{figure}
          \begin{tikzpicture}[scale=0.4]
            % sarrera-geruza
            \foreach \i in {1,...,\sarrera} {
              \node[circle, fill=orange!30] (Sarrera-\i) at (0,-\i) {};
            }
            % geruza ezkututa
            \foreach \i in {1,...,\ezkututa} {
              \node[circle, fill=teal!50, yshift=(\ezkututa-\sarrera)*2mm ] (Ezkututa-\i) at (2.5,-\i) {};
            }
            % irtee-geruza
            \foreach \i in {1,...,\irteera} {
              \node[circle, fill=purple!50, yshift=(\irteera-\sarrera)*2mm  ] (Irteera-\i) at (5,-\i) {};
            }
            % Sarreratik Ezkutura geziak marraztu
            \foreach \i in {1,...,\sarrera} {
              \foreach \j in {1,...,\ezkututa} {
                \draw[->, shorten >=1pt] (Sarrera-\i) -- (Ezkututa-\j);
              }
            }
            % Ezkututik Irteerera geziak marraztu
            \foreach \i in {1,...,\ezkututa} {
              \foreach \j in {1,...,\irteera} {
                \draw[->, shorten >=1pt] (Ezkututa-\i) -- (Irteera-\j);
              }
            }
            % Sarrerak 
            \foreach \i in {1,...,\sarrera} {
              \draw[<-, shorten <=1pt] (Sarrera-\i) -- ++(-1,0) node[left]{$x_{\i}$}; 
            }
            % Irteerak
            \foreach \i in {1,...,\irteera} {
              \draw[->, shorten <=1pt] (Irteera-\i) -- ++(1,0) node[right]{$y_{\i}$};
            }
          \end{tikzpicture}
          \caption{\tiny TALN}
        \end{figure}
      \end{minipage}
  \end{itemize}
\end{frame}
%****************************************************************
% Paralelismo : partekatu edo banatu
%****************************************************************
\begin{frame}{Parallèlisme}{partagé/distribué}
\pause
La mémoire utilisée peut être distribuée ou partagée.
  \begin{itemize}[<+->]
    \item mémoire partagée : on a des threads (fils d'exécution) ou tâches qui accèdent à une mémoire commune. 
      \begin{itemize}
        \item[\pozik] rapidité d'accès en lecture/écriture
        \item[\kontuz] accés concurrents : utilisation de verrous ou d'opérations atomiques
        \item[\argi] cibles : Threads Posix, OpenMP, CUDA (Compute Unified Device Architecture)
      \end{itemize}
    \item mémoire distribuée : chaque processus a une mémoire privée et communique avec les autres par des messages
      \begin{itemize}
        \item[\argi] nécéssaire sur de très grands problèmes (limite mémoire/nœud moins gênante)
        \item[\triste] l'envoi de messages peut être couteux
        \item[\argi] cibles : MPI, Multi-GPU
      \end{itemize}
  \end{itemize}
\end{frame}

%****************************************************************
% Paralelismoa : alea
%****************************************************************
\begin{frame}{Parallèlisme}{Grain}
\begin{itemize}[<+->]
  \item[\faTruck] gros grain : un processeur parallèle (tâche, threads, processus MPI) traite beaucoup d'éléments 
   \begin{itemize}
     \item décomposition de domaine (maillage, matrice) :  ex. MUMPS
     \item parallélisme par tâches (ex : STARPU)
     \item[\hand] chaque processeur doit avoir suffisament de mémoire pour traiter une grosse tâche
     \item[\argi] nombre raisonnable de tâches
   \end{itemize}
 \item[\faBicycle] grain fin : chaque processeur traite une «donnée élémentaire»
   \begin{itemize}
     \item[\hand] nécessite un grand nombre de «threads»
     \item[\hand] le changement de contexte doit être négligeable
     \item[\argi] très grand nombre de tâches $\geqslant 10000$
   \end{itemize}
\end{itemize}
\end{frame}

%****************************************************************
% Paralelismoa : arkitektura
%****************************************************************
\begin{frame}{Parallèlisme}{Architecture}
\begin{itemize}[<+->]
  \item homogène : caractéristiques semblables(latence, mémoire, etc)
   \begin{itemize}
     \item processeurs vectoriels (Cray, DEC)
     \item modèle SIMD : MMX, SSE, AVX, Altivec
     \item grappe de calcul MPI avec des nœuds identiques
   \end{itemize}
  \item hétérogène : disparités entre les processeurs
   \begin{itemize}
     \item Calcul sur GPU : hôte vs accélérateur
     \item \begin{minipage}[r]{0.49\linewidth} 
         Processeur Cell dans les PS3 
      \end{minipage}
      \begin{minipage}[r]{0.49\linewidth}
        \includegraphics[width=0.6\linewidth]{fig/ps3_lauso.jpg}
      \end{minipage}
\end{itemize}
\end{itemize}
\pause
  \hand\  La programmation sur GPU est {\it grosso modo}\  donc un parallélisme à {\bf grain fin}, à mémoire {\bf partagée} tournant sur
  une architecture {\bf hétérogène}.
\end{frame}

%****************************************************************
% sarrera : memoria eta cachea (eskema)
%****************************************************************
\begin{frame}{Mémoire et Cache (I)}
\begin{itemize}[<+->]
  \item La rapidité d'exécution d'un calcul dépend aussi de la «proximité» avec le CPU de l'élément de mémoire à traiter 
  \item[\gezi] les concepteurs de CPU ont créé des {\bf caches} pour stocker les valeurs mémoires les plus utilisées
  \begin{center}
    \colorbox{white}{\includegraphics[width=0.7\linewidth]{fig/cpu_classique.eps}}
  \end{center}
\end{itemize}
\end{frame}

%****************************************************************
% sarrera : latentzia
%****************************************************************
\begin{frame}{Mémoire et Cache (II) : latence}
\pause
  \begin{itemize}[<+->]
  \item ainsi la latence $l$ de l'emplacement mémoire auquel on accède  respecte
  $$l({\mbox{\scriptsize registre}}) \leqslant l(\mbox{\scriptsize cache L1}) \leqslant
    l(\mbox{\scriptsize cache L2}) \leqslant l(\mbox{\scriptsize mémoire globale}).$$
  \item ordres de grandeur des latences (core i7 Xeon E5500)
    \begin{tabular}{|l|c|c|}
    \hline
      type & nb cycles & latence (ns)  \\
    \hline
      cache L1  &  4 & 2 \\
      cache L2  &  10 & 5 \\
      cache L3 (non partagé) & 40 & 20  \\
      cache L3 (partagé) &  65 & 35  \\
      mémoire vive locale & & 60 \\
      mémoire vive distante & & 100 \\
    \hline
    \end{tabular}
  \end{itemize}
\end{frame}

%%****************************************************************
%% sarrera : arrakasta ta huts
%%****************************************************************
\begin{frame}{Cache : Succès et défauts}
\begin{itemize}[<+->]
  \item[\pozik] succès (hit) : accès déjà dans la ligne de cache 
  \item[\triste] défaut (miss) : accès hors de la ligne de cache \gezi\ il faut recharger entièrement la ligne de cache!
  \item[\argi] un code localisant ses accès dans le cache minimise les défauts de cache et tourne plus vite
  \item[\adibi] double boucle en \mylang\,  sur les lignes (resp. colonnes en \othlang)
\begin{minipage}[c]{0.49\linewidth}
  \includeSrc{code/loop_col}
\end{minipage}
\begin{minipage}[r]{0.49\linewidth}
    \begin{tabular}{|c|c|}
    \hline
     boucle ext en \mylang\, & tps(s)  \\
    \hline
      \ifC
      i (lignes) & 2.7s \\
      j (cols) & 3.4s \\
      \else
      j (cols) & 2.7s \\
      i (lignes) & 3.4s \\
      \fi
    \hline
    \end{tabular}
\end{minipage}
\item[\hand] raison d'être des biblios BLAS et LAPACK
\end{itemize}
\end{frame}


\ifC
\begin{frame}{Interlude sur les Pointeurs}
  \lstset{basicstyle=\relsize{-1}\ttfamily}
\begin{itemize}[<+->]
  \item Un pointeur est une variable contenant l'adresse d'une autre
  \item déclaration : \lstinline! int * p; // p est pointeur sur des ints !
  \item allocation  : \lstinline! p = (int *) malloc(4*sizeof(int)); // alloue 4 entiers !
  \item désallocation : \lstinline! free(p); // libere la memoire !
  \item déréfencement : \lstinline! *p = 2 ;! ou \lstinline !p[0] = 2;!
  \item «adresse de» : \lstinline! int t[] = \{1,2,3\} ; p=\&t[0] ; (*p)++;!
  \item[\argi] \lstinline!*! $\circ$ \lstinline!\&! = $I_{valeurs}$ et \lstinline!\&! $\circ$ \lstinline!*! = $I_{adresses}$
  \item arithmétique : \lstinline! for(p=\&t[0]; p\!=\&t[0]+3;) (*(p++))++; !
  \item[\scout] notation : \lstinline! p[i] ! $\equiv$ \lstinline! *(i+p)! $\equiv$ \lstinline! i[p]!
  \item utilisation 
    \begin{itemize}
      \item passage par adresse des arguments de fonction
      \item gestion de mémoire
    \end{itemize}
\end{itemize}
  \lstset{basicstyle=\relsize{-3}\ttfamily}
\end{frame}
\fi
\begin{frame}{Mode de passage des arguments}
\begin{columns}[t]
\pause
\column{5cm}
 passage par valeur
  \includeSrc{code/valeur}
  renvoie \lstinline! p=3,x=2!
  \begin{itemize}
    \item[\triste] {\tt f} ne peut pas changer {\tt x}
    \item[\kontuz] dépassement de pile possible !
   \end{itemize} 
\pause
\column{5cm}
 passage par adresse
  \includeSrc{code/adresse}
  renvoie \lstinline! p=3,x=3!
  \begin{itemize}
    \item[\scout] {\tt f} peut changer {\tt x}
    \item[\argi] économise de la place sur la pile
   \end{itemize} 
\end{columns}
  \begin{center}
    \ifC le C passe les arguments par {\bf valeur } \else Fortran passe les arguments par {\bf adresse } \fi par défaut
  \end{center} 
\end{frame}
%***************************************************************
% Allocation de mémoire
%***************************************************************
\begin{frame}{Allocation de mémoire}
La mémoire sur l'hôte (hors registre) est allouée de 3 façons: 
\begin{itemize}[<+->]
  \item statique : réservé lors de la compilation ({\tt text, data ou bss})
    \begin{itemize}
      \item[\pozik] allocation rapide (coût nul) et quasi-illimité
      \item[\pozik] sûr (pas de fuites de mémoire possibles)
      \item[\triste] peu flexible
    \end{itemize}
  \item automatique : alloué sur la pile (\og{}stack\fg{}) lors de l'appel d'une fonction
    \begin{itemize}
      \item[\scout] permet de stocker : 
      \begin{itemize}
        \item les variables locales d'une fonction
        \item l'adresse de retour de l'appel
        \item les paramètres d'appel de la fonction
      \end{itemize}
    \item[\argi] désalloué au retour de la fonction fonction
      \item[\pozik] allocation/désallocation rapide
      \item[\kontuz] limité par la taille de la pile
    \end{itemize}
  \item dynamique : alloué sur le tas (\og{}heap\fg{}) lors de l'exécution
  \begin{itemize}
      \item[\pozik] très flexible et quasi-illimité
      \item[\triste] moins favorable au cache
      \item[\triste] allocation/désallocation lente
      \ifC \item[\kontuz] à la discrétion du codeur \gezi fuites possibles de mémoire \else \fi
    \end{itemize}
\end{itemize}
\end{frame}
\begin{frame}{Quizz allocation sur hôte}
  \lstset{numbers=none}
  \begin{itemize}
    \pause
    \item[\scout] 3 programmes allouent le même tableau de 3 façons différentes
\begin{columns}[T]
\pause
  \begin{column}{4cm}
  \includeSrc{code/mem1}
     \ifC
     \lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt]{code/mem1.out}
     \else
     \lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt]{code/mem1f.out}
     \fi
\end{column}
\pause
  \vrule{}
  \begin{column}{4cm}
  \includeSrc{code/mem2}
  \ifC
  \lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt]{code/mem2.out}
  \else
  \lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt]{code/mem2f.out}
  \fi
  \end{column}
\pause
  \vrule{}
  \begin{column}{4cm}
  \includeSrc{code/mem3}
  \ifC
    \lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt]{code/mem3.out}
  \else
    \lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt]{code/mem3f.out}
  \fi
  \end{column}
\end{columns}
    \pause
    \item[\galde] Quel est le type de chaque allocation ?
  \end{itemize}
\begin{textblock}{12}(0.2, 8)
  \uncover<7-9>{
	\tikz \node[fill=red, text=white, rounded corners=2mm,
	inner sep=5mm, rotate=20]{
	  \large{\textbf{Automatique}}
	};
  }
\end{textblock}

\begin{textblock}{12}(6, 7)
  \uncover<8-9>{
	\tikz \node[fill=green, text=white, rounded corners=2mm,
	inner sep=5mm, rotate=20]{
	  \large{\textbf{Statique}}
	};
  }
\end{textblock}

\begin{textblock}{12}(11, 8)
  \uncover<9-9>{
	\tikz \node[fill=orange, text=white, rounded corners=2mm,
	inner sep=5mm, rotate=20]{
	  \large{\textbf{Dynamique}}
	};
  }
\end{textblock}

\end{frame}
  \lstset{numbers=left}
\end{document}
%****************************************************************
%  Passage a l'echelle (fort) 
%****************************************************************
\begin{frame}{Passage à l'échelle fort}
\begin{itemize}[<+->]
  \item[\egia] taille de problème fixe
  \item[\scout] temps de calcul décroit lorsque \# procs augmente
  \item[\argi] gain maximum (loi d'Amdhal)
\begin{equation*}
G = \frac{1}{(1-P)+ \frac{P}{N}}
\end{equation*}
où $P$ est la fraction de code //isable et $N$ est le \# procs
 \item[\scout] «passage à l'echelle» linéaire fort \geziBikoitz  $G = N$
 \item[\adibi] $P = 0.75$ \gezi $G = 4$ \triste
 \item[\hand] il faut parallèliser la plus grande partie du code possible
 \item[\kontuz] sur GPU, la plus grande partie du code doit tourner sur l'accélérateur
\end{itemize}
\end{frame}

%****************************************************************
%  Passage a l'echelle (faible) 
%****************************************************************
\begin{frame}{Passage à l'échelle faible}
\begin{itemize}[<+->]
  \item[\egia] taille de problème par processeur {\bf fixé}
  \item[\scout] le problème passe à l'échelle lorsque \# procs augmente (taille réelle augmente)
  \item[\argi] le gain est donnée par la loi de Gustafson
\begin{equation*}
G = (1-P) + N\cdot P
\end{equation*}
 \item[\scout] pas de limite théorique
 \item[\kontuz] le temps de calcul n'est pas diminué
\end{itemize}
\end{frame}

%%****************************************************************
%% Exemple introductif (verse séquentielle)
%%****************************************************************
\begin{frame}{Exemple d'introduction}{version séquentielle}
\pause
\begin{itemize}[<+->]
  \item[\adibi] soit un programme calculant \texttt{tab[:]} $\leftarrow$ \texttt{tab[:] + 3}
  \includeSrc{code/increment}
   \item[\galde] on souhaite paralléliser la boucle en ligne \ifC 6 \else 15 \fi à l'aide de CUDA
\end{itemize}
\end{frame}

%%****************************************************************
%% Exemple introductif (CUDA)
%%****************************************************************
\begin{frame}{Exemple d'introduction}{version CUDA}
\pause
\begin{itemize}[<+->]
  \item[\adibi] on peut écrire le programme suivant
\includeSrcCu{code/increment}
\ifC \item[\pozik] plus de boucle \fi
\item[\argi] nouveaux mot-clefs : \ifC \texttt{\_\_global\_\_, threadIdx} \else
\texttt{global, threadIdx} \fi
\item[\argi] appel du noyau \texttt{increment<<<1,N>>>}
\ifC
\item[\argi] gestion de la mémoire : \texttt{\small cudaMemcpy, cudaMalloc, cudaFree}
\fi
\end{itemize}
\end{frame}

%****************************************************************
% Exemple introductif principe
%****************************************************************
\begin{frame}{Exemple d'introduction}{explication}
\pause
\begin{itemize}[<+->]
 \item[\argi] boucle \ifC \texttt{for} \else \texttt{do} \fi  \gezi\ appel d'un {\bf thread}
 \item[\argi] exécutant le noyau \texttt{increment}
 \item[\argi] pour chaque indice de boucle indexé par \texttt{threadIdx\spt x} 
 \item[\argi] sur le tableau \texttt{tab\_d} alloué sur le GPU
 \item[\kontuz] il faut copier \texttt{tab} sur le GPU et le rapatrier après calcul
\end{itemize}
\pause
\begin{center}
  \colorbox{white}{\includegraphics[width=0.9\linewidth]{fig/parallel.eps}}
\end{center}
\end{frame}

%****************************************************************
% Déroulé classique d'un calcul
%****************************************************************
\begin{frame}{Déroulé typique d'un calcul}
  \lstset{basicstyle=\ttfamily}
\pause
  \begin{itemize}[<+->]
    \item[\argi] un programme CUDA suit généralement les étapes suivantes 
\begin{enumerate}[<+->]
 \item \ifC \else (optionel) \fi allouer la mémoire sur le GPU : \lstinline!cudaMalloc!
 \item \ifC \else (optionel) \fi copier depuis la mémoire globale vers le GPU : \lstinline!cudaMemCpy( ... ,cudaMemcpyHostToDevice)!
 \item exécuter le noyau sur l'accélerateur : \ifC \lstinline!myKernel<<<...,...>>>(...)! 
 \else \lstinline!call myKernel<<<...,...>>>(...)! \fi
 \item \ifC \else (optionel) \fi rapatrier les résultats en mémoire globale \lstinline!cudaMemCpy(...,cudaMemcpyDeviceToHost)!
 \item \ifC \else (optionel) \fi libérer la mémoire sur le GPU \lstinline!cudaFree!
 \item visualiser les résultats
\end{enumerate}
\item[\geldi] Avant de poursuivre, nous avons besoin le fonctionnement d'un GPU
\end{itemize}
\end{frame}
\begin{frame}{Architecture GPU}
\begin{itemize}[<+->]
  \item[\scout] un GPU comprend 
   \begin{itemize} 
     \item des multiprocesseurs de flux (SM)
     \item de la mémoire globale (DRAM)
   \end{itemize} 
  \item que l'on peut schematiser comme suit
  \begin{center}
    \colorbox{white}{\includegraphics[width=0.8\linewidth]{fig/archi_gpu.eps}}
  \end{center}
  \item[\kontuz] ne pas confondre la mémoire globale de l'hôte et celle de l'accelérateur!
\end{itemize}
\end{frame}
%****************************************************************
% Modèle d'execution GPU I
%****************************************************************
\begin{frame}{Modèle d'exécution du GPU}{exemple sur un Tesla C1060}
\begin{minipage}[c]{0.49\linewidth}
\begin{itemize}
  \item multiprocesseur de flux (SM)
    \begin{itemize}
      \item groupe de 8 processeurs de flux (SP)
        \begin{itemize}
          \item partage de mémoire locale
          \item synchronisation
        \end{itemize}
    \end{itemize}
  \item processeur de flux (SP) : 
    \begin{itemize}
    \item 64KB de registres, 
    \item {\bf threads} : ensemble de registres
    \begin{itemize}
      \item création/destruction gratuites
    \end{itemize}
  \item exécution entrelacée de {\em threads} matériels : jusqu'à 128 par SP
    \end{itemize}
\end{itemize}
\end{minipage}
\begin{minipage}[c]{0.49\linewidth}
\begin{center}
  \includegraphics[width=0.6\linewidth]{fig/GPUArchiThread.eps}
\end{center}
\end{minipage}
\end{frame}

%****************************************************************
% Modèle d'execution GPU II
%****************************************************************
\begin{frame}{Modèle d'exécution du GPU}{exemple sur un Tesla C1060 (II)}
\begin{minipage}[c]{0.49\linewidth}
\begin{itemize}
  \item 1 seule unité d'envoi d'instruction par multiprocesseur de flux
    \begin{itemize}
      \item tous les SPs exécutent la même instruction au même cycle d'horloge
        \begin{itemize}
          \item sur des données différentes (SIMD)
        \end{itemize}
    \end{itemize}
  \item l'unité d'envoi prend 4 cycles pour récupérer et décoder les instructions
    \begin{itemize}
      \item 4 groupes de 8 {\bf threads} planifiés / ligne
    exécutant la même instruction
      \item changement de contexte gratuit !
    \end{itemize}
\end{itemize}
\end{minipage}
\begin{minipage}[c]{0.49\linewidth}
\begin{center}
  \includegraphics[width=0.9\linewidth]{fig/GPUArchi8Thread.eps}
\end{center}
\end{minipage}
\end{frame}

%****************************************************************
% Modèle d'execution GPU III
%****************************************************************
\begin{frame}{modèle d'exécution du GPU}{warps et demi-warps}
\begin{minipage}[c]{0.69\linewidth}
\begin{itemize}
  \item {\bf fils d'exécution}(threads) sont implicitement groupés en {\bf chaîne}(warp)
    \begin{itemize}
      \item un chaîne = 32 threads 
      \item tous les threads d'une même chaîne exécutent la même instruction au même cycle logique
        \begin{itemize}
          \item[\kontuz] \alert{pas de divergence!}
        \end{itemize}
    \end{itemize}
  \item chargement depuis la DRAM coûteux : ratio latence(DRAM) / instruction = 128 \gezi 128 threads pour recouvrir la latence !
\end{itemize}
\end{minipage}
\begin{minipage}[c]{0.29\linewidth}
\begin{center}
  \includegraphics[width=0.95\linewidth]{fig/GPUArchi8ThreadDiv.eps}
\end{center}
\end{minipage}
\end{frame}
%****************************************************************
% Modèle d'execution GPU IV
%****************************************************************
\begin{frame}{modèle d'exécution du GPU}{exemple avec un T4}
\begin{minipage}[c]{0.69\linewidth}
  \begin{itemize}[<+->]
    \item Tesla T4 : 
      \begin{itemize}
        \item 40 SM, 64 SP / SM $\Rightarrow$ 2560 SP
        \item 1024 threads max / SM $\Rightarrow$ 40960 threads
      \end{itemize}
    \item threads «spéciaux»
      \begin{itemize}
        \item parallélisme de données respectant des motifs d'accès régulier
      \end{itemize}
  \end{itemize}
\end{minipage}
\begin{minipage}[c]{0.29\linewidth}
\begin{center}
  \rotatebox{90}{\includegraphics[width=0.9\linewidth]{fig/104.jpg}}
\end{center}
\end{minipage}
\end{frame}

%****************************************************************
% Organisation des threads
%****************************************************************
\begin{frame}{Organisation des threads}{découpage des données}
 \pause
 \begin{minipage}[c]{0.59\linewidth}
  \begin{itemize}[<+->]
    \item[\argi] Tesla T4 $\approx$ 41K threads 
    \item[\galde] Que faire si $N \geq 41K$ ?
    \item[\scout] on découpe les données en blocs
    \item[\argi] threads organisés en {\em blocs} qui tournent chacun sur 1 SM
    \item[\argi] une {\bf grille} répartie les blocs sur tous les SMs
    \item[\argi] on paramètre l'appel du noyau \texttt{myKernel<<<dg,db>>>} 
      \begin{itemize}
        \item dg : taille grille (\texttt{int} ou \texttt{dim3})
        \item db : taille bloc (\texttt{int} ou \texttt{dim3})
      \end{itemize}
  \end{itemize}
\end{minipage}
\begin{minipage}[c]{0.39\linewidth}
\begin{center}
  \colorbox{white}{\includegraphics[width=0.8\linewidth]{fig/grille_et_blocs.eps}}
\end{center}
\end{minipage}
\end{frame}

%****************************************************************
% Organisation des threads II
%****************************************************************
\begin{frame}{Organisation des threads}{ordonnancement}
 \pause
 \begin{minipage}[c]{0.59\linewidth}
   {\bf Le programme sur l'hôte demande l'exécution d'une grille de blocs de threads}
  \begin{itemize}[<+->]
    \item l'ordonnanceur de bloc distribue les blocs sur les SMs
    \item[\kontuz] des GPUs différents peuvent exécuter différemment la même grille de blocs
  \end{itemize}
\end{minipage}
\begin{minipage}[c]{0.39\linewidth}
\begin{center}
  \colorbox{white}{\includegraphics[width=0.95\linewidth]{fig/bloc_ordonanceur.eps}}
\end{center}
\end{minipage}
\end{frame}

%****************************************************************
% Tailles des grilles/blocs 
%****************************************************************
\begin{frame}{Tailles de grille et de blocs}
  \begin{itemize}[<+->]
    \item[\argi] type CUDA pour gérer les dimensions de grille et de bloc
    \begin{itemize}
      \item \alert{dim3} est une structure avec 3 champs entiers \texttt{\_\spt x,\_\spt y et \_\spt z}
      \item soit \texttt{dg} un descripteur de grille et \texttt{db} un descripteur de bloc
    \end{itemize}
  \item[\argi] Limites de bloc 3D
   \begin{itemize}
     \item \texttt{db\spt x} $\leqslant 1024$, \texttt{db\spt y} $\leqslant 1024$, \texttt{db\spt z} $\leqslant 64$ 
     \item nb total de threads par bloc $\leqslant 1024$
     \item problèmes 2D \gezi\  \texttt{db\spt z} = 1 
     \item problèmes 1D \gezi\  \texttt{db\spt z} = \texttt{db\spt y} = 1
   \end{itemize}
 \item[\argi] limites de la grille 3D
   \begin{itemize}
      \item \texttt{dg\spt x} $\leqslant 2^{31}-1$, \texttt{dg\spt y} $\leqslant 2^{16} - 1 $, \texttt{dg\spt z} $\leqslant 2^{16}-1$
      \item nb total de threads par bloc $\leqslant 1024$
      \item problèmes 2D \gezi\  \texttt{dg\spt z} = 1 
      \item problèmes 1D \gezi\  \texttt{dg\spt z} = \texttt{dg\spt y} = 1
    \end{itemize}
  \item[\adibi] exemple avec données 2D mais une grille 1D
    \includeSrc{code/grille}
  \end{itemize}
\end{frame}

%****************************************************************
% Tailles des grilles/blocs
%****************************************************************
\begin{frame}{Taille de blocs}
  \begin{itemize}[<+->]
    \item[\scout] Pour des raisons d'alignement on choisit toujours des blocs de taille multiple de 32 (ou 16 pour les archi $\leqslant$ 1.x)
    \item[\galde] comment faire si les données ne sont pas multiples de la taille du bloc ?
    \item[\argi] on alloue en faisant un dépassement systématique et on fait une vérification dans le noyau
    \item exemple : pour une grille 1D
  \begin{itemize}
    \item[\egia] on choisit \texttt{GRID\_SIZE} = (N-1) / \texttt{BLOCK\_SIZE} + 1
\begin{center}
  \colorbox{white}{\includegraphics[width=0.7\linewidth]{fig/grille_1D.eps}}
\end{center}
\ifC
   \item[\egia] \texttt{\small currentIndex = blockDim.x * blockIdx.x + threadIdx.x}
\else
   \item[\egia] \texttt{\small currentIndex = blockDim\%x * (blockIdx\%x - 1) + threadIdx\%x}
\fi
   \item[\kontuz] penser à vérifier que \texttt{currentIndex} \ifC $<$ \else $\leq$ \fi N !
 \end{itemize}
  \end{itemize}
\end{frame}

%****************************************************************
% Tailles des grilles/blocs
%****************************************************************
\begin{frame}{Taille de blocs}{Exemple XOR}
\begin{flushright}
\includegraphics[width=0.1\linewidth]{fig/xor.jpg}
\end{flushright}
  \includeSrcCu{code/overflow}
\end{frame}

%****************************************************************
% Coalescence
%****************************************************************
\begin{frame}{Coalescence}
  \begin{itemize}[<+->]
    \item[\argi] chaîne (warp) permet jusqu'à 32 accès mémoire concurrents
    \item[\argi] un accès mémoire typique $\thicksim$ 4 octets
    \item[\argi] granularité mémorielle : de 32 à 128 octets 
    \item[\harritu] {\em coalescence} : agrégation de plusieurs accès mémoire en un seul lorsqu'il se font dans le même bloc
    \item[\adibi] exemples avec 4 «threads» par chaîne et 4 mots par transaction
\begin{center}
  \colorbox{white}{\includegraphics[width=0.6\linewidth]{fig/coalescence.eps}}
\end{center}
  \end{itemize}
\end{frame}

%****************************************************************
% Coalescence
%****************************************************************
\begin{frame}{Coalescence}{Accès mémoires contigus}
  \begin{itemize}[<+->]
    \item[\adibi] soit le code d'homothétie d'un vecteur
\begin{center}
\includeSrcCu{code/scale}
\end{center}
    \item[\argi] on a des accès {\em contigus}, ce qui autorise la coalescence
\begin{center}
  \vspace{0.5cm}
  \colorbox{white}{\includegraphics[width=0.8\linewidth]{fig/coalScale.eps}}
\end{center}
  \end{itemize}
\end{frame}

%****************************************************************
% Coalescence
%****************************************************************
\begin{frame}{Coalescence}{Accès mémoires non contigus}
  \begin{itemize}[<+->]
    \item[\adibi] on peut y accéder différement, par exemple avec un pas de 2
\begin{center}
  \includeSrcCu{code/scaleFlipAndHalf}
\end{center}
    \item[\kontuz] mais les tranferts mémoires sont non-coalescents !
\begin{minipage}[c]{0.49\linewidth}
  \colorbox{white}{\includegraphics[width=0.9\linewidth]{fig/coalScaleHalf.eps}}
\end{minipage}
\begin{minipage}[r]{0.49\linewidth}
  \vspace{1cm}
  \begin{figure}[h]
    \begin{tabular}{|c|c|}
      \hline
      noyau & tps($\mu$s)  \\
      \hline
      contigu & 155 \\
      non-contigu  & 243 \\
      \hline
    \end{tabular}
    \caption{Tesla T4: $N = 2^{22}$}
  \end{figure}
\end{minipage}
  \end{itemize}
\end{frame}

%****************************************************************
% Coalescence
%****************************************************************
\begin{frame}{Quizz}{Tableau de Structures ou Structure de Tableaux}
  \begin{itemize}[<+->]
    \item[\adibi] On veut écrire un noyau qui translate des particules , {\em i.e. }  $x[i] = x[i] + dx[i]$
    \item[\galde] un «tableau de structures»
\begin{center}
  \includeSrc{code/AOS}
\end{center}
    \item[\galde] ou une «structure de tableaux»
\begin{center}
  \includeSrc{code/SOA}
\end{center}
  \item[\hand] réponse en TP \pozik
  \end{itemize}
\end{frame}

%****************************************************************
% Déverminage
%****************************************************************
\begin{frame}{Déverminage : fonctions de l'API CUDA}
  \begin{itemize}[<+->]
    \item[\kontuz] toujours vérifier les retours de fonction 
\begin{center}
  \lstinputlisting[language=C]{code/retour.c}
\end{center}
    \item[\argi] chaque fonction de l'API renvoie un \texttt{cudaError\_t}
    \item[\scout] la macro \texttt{checkCudaError} récupère les erreurs CUDA
\begin{center}
  \lstinputlisting{code/check.c}
\end{center}
  \end{itemize}
\end{frame}

%****************************************************************
% Déverminage : outils I
%****************************************************************
\begin{frame}{Déverminage}
  \begin{itemize}[<+->]
        \item[\scout] si $CC \geqslant 2.x$, \texttt{printf} fonctionne depuis un noyau 
        \item[\argi] inclusion des symboles \texttt{nvcc -g -G monProg.cu -o myProg}
   \end{itemize}
\pause
  \lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt, lastline=11]{code/outGDB}
  \begin{itemize}[<+->]
    \item[\argi] commandes classiques : \texttt{run}, \texttt{break}, \texttt{cont}, 
    \item[\argi] commandes cuda : \texttt{info cuda threads}, \texttt{break}, \texttt{cont}, 
   \end{itemize}
\end{frame}

%****************************************************************
% Déverminage : outils I
%****************************************************************
\begin{frame}{Déverminage mémoire (CUDA 10)}{cuda-memcheck}
  \lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt]{code/outMemcheck}
\end{frame}

%****************************************************************
% Déverminage : outils I
%****************************************************************
\begin{frame}{Déverminage mémoire (CUDA 11)}{\texttt{compute-sanitizer}}
  \lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt]{code/outComputeSanitizer}
\end{frame}

%****************************************************************
% Profilage : 
%****************************************************************
\begin{frame}{Profilage par évènements}
  \begin{itemize}[<+->]
    \item[\argi] un \og{}évenement\fg{} CUDA permet de mesurer le temps d'exécution d'un noyau
\begin{center}
  \lstinputlisting[language=C]{code/exProfile.c}
\end{center}
   \item[\kontuz] \texttt{cudaEventElapsedTime} renvoie un temps en milliseconds
   \item[\pozik] on peut automatiser des mesures de profilage.
  \end{itemize}
\end{frame}

%****************************************************************
% Profilatzea
%****************************************************************
\begin{frame}{Profilage : \texttt{nvprof} (CUDA 10)}
  \begin{itemize}[<+->]
    \item[\pozik] beaucoup plus de métriques et de compteurs disponibles
    \item[\triste] extraction automatique de résultats plus compliquée (merci \texttt{grep})
    \item[\argi] afficher une trace {\tt --print-gpu-trace }
  \end{itemize}
\pause\lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt]{code/outProfile}
\end{frame}

%****************************************************************
% Profilatzea
%****************************************************************
\begin{frame}{Profilage : \texttt{ncu} (CUDA 11)}
  \begin{itemize}[<+->]
    \item[\pozik] beaucoup plus de métriques et de compteurs disponibles
  \end{itemize}
\pause\lstinputlisting[numbers=none,language=bash,basicstyle=\relsize{-5}\ttfamily,lineskip=2pt]{code/outProfile}
\end{frame}


%****************************************************************
% Optimizazio
%****************************************************************
\begin{frame}
  \begin{center}
    {\Huge Seconde partie : Optimisation}
  \end{center}
\end{frame}

%****************************************************************
% Limites 
%****************************************************************
\begin{frame}{Facteur limitants}{Petite experience}
  \begin{itemize}[<+->]
    \item soit le noyau \texttt{base} en 3 versions
      \lstinputlisting[language=C]{code/pratique.c}
    \item on chronomètre l'exécution (en $\mu$s) avec $N=8Mo$ 
    \begin{minipage}[l]{0.49\linewidth}
      \begin{center}
        \begin{tabular}{|l |l|r|r|r|}
          \hline
          GPU & modèle    & base    & memory & math  \\ 
          \hline
          K40 &normal    &  468    &  390   &  236\\ 
              &fastmath  &  405    &  390   &  162 \\ 
          \hline
          T4 & normal    &  361    &  320   &  187\\ 
             & fastmath  &  326    &  321   &  148 \\ 
          \hline
        \end{tabular}
      \end{center}
    \end{minipage}
  \end{itemize}
\end{frame}
%****************************************************************
% mugatzaileak
%****************************************************************
\begin{frame}{Facteur limitants}{Mémoire, instruction ou latence}
  \begin{itemize}[<+->]
    \item limitation par les {\bf instructions} (compute bound) 
      \begin{itemize}
        \item sans {\tt fastmath} : utilisation préponderante du calcul
      \end{itemize}
    \item limitation par la {\bf mémoire } (memory bound) : 
      \begin{itemize}
        \item avec {\tt fasthmath} facteur mémoire préponderant
      \end{itemize}
    \item limitation par la {\bf latence} : utilisation faible de la mémoire et des calculs
      \begin{itemize}
        \item {\bf occupation} faible 
        \item calage des threads (dépendance d'executions, synchronisation, chargement d'instruction)
      \end{itemize}
\end{itemize}
\end{frame}
«»
%****************************************************************
% facteur limitants
%****************************************************************
\begin{frame}{Bande Passante(BP)}
  \begin{itemize}[<+->]
    \item débit de données en Go/s sur le bus mémoire du GPU (throughput)
    \item BP max théorique : $$BP_{\mbox{max}} = 2 \cdot \frac{F_{\mbox{max}} * N_{\mbox{bus}}}{10^6} $$
      \begin{itemize}
        \item $F_{max}$ : fréquence mémoire maximale (KHz) : \texttt{memoryClockRate}
        \item $N_{bus}$ : largeur de bus (octets) : \texttt{memoryBusWidth}/8
      \end{itemize}
    \item BP réelle d'un noyau : $$ BP_{\mbox{ker}} = \frac{\# R_{\ker} + \# W_{\ker}}{10^9 t_{\ker}} $$
      \begin{itemize}
        \item $\# R_{\ker}$ : nb de lectures du noyau (octets)
        \item $\# W_{\ker}$ : nb d'écritures du noyau (octets)
        \item $t_{\ker}$ : tps moyen d'exécution du noyau (s)
      \end{itemize}
  \end{itemize}
\end{frame}

%****************************************************************
% Performances 
%****************************************************************
\begin{frame}{Quelques performances}
  \begin{itemize}[<+->]
    \item la capacité de calcul (CC) dépend de l'architecture
    \item Flops = $\frac{Flops}{cycle}\times \mbox{\#cœurs} \times \frac{\mbox{cycle}}{\mbox{seconde}} \approx
         2\footnote{https://en.wikipedia.org/wiki/FLOPS} \times \mbox{\#cœurs} \times \mbox{Freq} $
       \item si (CC)  $\nearrow$ , le nombre de GFlops\; $\nearrow$ aussi \pozik
  \end{itemize}
\pause
 \begin{tabular}{|l|r|r|r|r|r|r|r|}
    \hline
      modèle            & C1060   & C2070 &  K40   &  P100  & V100  & T4 \\
    \hline
      architecture      & Tesla   & Fermi & Kepler & Pascal & Volta & Turing \\
      CC                & 1.3     & 2.0   & 3.5    &   6.0  &   7.0 & 7.5  \\
      Fréquence(Mhz)    & 1296    & 1150  &  745   &  1329  &  1380 & 1590 \\
      \# SM             & 30      & 14    &  15    &    56  &   80  & 40  \\
      \# SP (float)     & 240     & 448   &  2880  &  3584  &  5120 & 2560  \\
      Flops (G/s)       & 622     & 1030  &  4291  &  9526  &  14131 & 8141\footnote{65130 en demi-précision} \\
      BP$_{max}$ (Go/s) & 102     & 150   &  288   &   732  &  897   & 320 \\
    \hline
\end{tabular}
\end{frame}

%****************************************************************
% facteur limitants
%****************************************************************
\begin{frame}{Facteur limitants}{bande passante}
    En revenant à l'exemple précédent : temps(s) \gezi \ BP (Go/s)
      \begin{center}
        \begin{tabular}{|l |l|r|r|r|r|}
          \hline
          GPU & modèle    & base    & memory & math & $BP_{max}$ \\ 
          \hline
          K40 & normal    &  468    &  172   &  142 & 288\\ 
              & fastmath  &  405    &  172   &  207 & 288 \\ 
          \hline
          T4 & normal    &  185    &  209   &  179 & 320 \\ 
             & fastmath  &  205    &  209   &  226 & 320 \\ 
          \hline
        \end{tabular}
      \end{center}
\end{frame}

%****************************************************************
% facteur limitants
%****************************************************************
\begin{frame}{Facteur limitants}{Occupation}
  \begin{itemize} 
    \item définition 
      $$ \mbox{Occupation} = \frac{\mbox{nb de chaînes(warps) actives par SM}}{\mbox{nb max de chaînes par SM}} $$
    \item calcul 
      \begin{itemize}
        \item estimation : {\tt cudaOccupancyMaxActiveBlocksPerMultiprocessor }
        \item réelle : {\tt nvprof --metrics achieved\_occupancy } ou {\tt ncu --metrics  sm\_\_warps\_active.avg.pct\_of\_peak\_sustained\_active}
      \end{itemize}
    \item limité par l'allocation de la mémoire partagée
    \item influence le parallélisme au niveau des threads
  \end{itemize}
\end{frame}

%****************************************************************
% Modèle théorique
%****************************************************************
\begin{frame}[fragile]{BP vs occupation}
\begin{minipage}[c]{0.53\linewidth}
  
  \begin{itemize}
    \item[\argi] On peut borner la BP par une fonction affine par morceaux de l'occupation 
    \item[\scout] analogue d'un modèle \og{}roofline\fg{} pour CPU,
   \end{itemize}
\end{minipage}%
\begin{minipage}[c]{0.45\linewidth}
\begin{tikzpicture}[scale=0.8, domain=0:130]
\begin{axis}[
        axis x line=middle,
        axis y line=middle,
        xlabel={occupation},
        ylabel=\small{BP},
        ticks=none,
        xtick=\empty,
        ytick=\empty,
        axis line style={->},
        xmin = 0., xmax = 130,
        ymin = 0., ymax = 40]
        \addplot[
                domain = 0:130,
                samples =400
        ] {min(x,30)};
        \node[above] at (axis cs:63,29.5){\small{limite de bande passante}};
        \addplot[line width=2pt,
                domain = 0:130,
                samples =400
        ] {30*(1-exp(-(x-1.)/30.)))};
        \node[rotate=70] at (axis cs:15,20) {\small{limite de latence}};
\end{axis}
\end{tikzpicture}
\end{minipage}
  \begin{itemize}
    \item[\kontuz] $$ \mbox{Occupation}  \neq \mbox{Intensité Arithmetique} $$
  \end{itemize} 
 \end{frame}
    
%%****************************************************************
%%  Parallèlisme d'instruction
%%****************************************************************
\begin{frame}{Parallelisme d'instruction}
\pause
\begin{itemize}[<+->]
	\item[\kontuz] une occupation elevée n'est pas le seul moyen de masquer la latence \harritu
    \item[\adibi] soit le noyau de copie suivant
	\lstinputlisting[language=C, firstline=9, lastline=15]{code/occupancy-copy.c}
    \item[\argi] on peut augmenter sa BP en parallélisant des instructions
	\lstinputlisting[language=C, firstline=17, lastline=27]{code/occupancy-copy.c}
\end{itemize}
\end{frame}
%%****************************************************************
%%  Graphiques
%%****************************************************************
\begin{frame}{Comparaisons des noyaux}
\begin{figure}[h!]
  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[grid=major, legend entries={copy, copy\_ilp}, xlabel=occupation(\%), ylabel=BP(Go/s) ]
        \addplot 
        table[x=occ1,y=bp1,col sep=comma] {fig/val_mes.csv}; 
		\addplot 
        table[x=occ2,y=bp2,col sep=comma] {fig/val_mes.csv}; 
        %\draw[red] (axis cs:\pgfkeysvalueof{/pgfplots/xmin},160) -- (axis cs:\pgfkeysvalueof{/pgfplots/xmax}, 160);
       \end{axis}
    \end{tikzpicture}
    \caption{Performances des noyaux de copie}
  \end{center}
\end{figure}
\end{frame}

%****************************************************************
% transferentziak
%****************************************************************
\begin{frame}{Transferts Hôte \geziBikoitz\  GPU}{Ordres de grandeur}
  \begin{itemize}[<+->]
    \item[\argi] BP DRAM GPU \geziBikoitz\ SMs $\thicksim$ 200-300 (Go/s)
    \item[\argi] BP Mémoire Globale \geziBikoitz\ DRAM GPU $\thicksim$ 10-20 (Go/s)
    \item[\scout] il faut donc optimiser les transferts hôte \geziBikoitz\ GPU
      \begin{itemize}
        \item mémoire verrouillée
        \item transferts asynchrones
      \end{itemize}
    \item[\kontuz] on a beau avoir le noyau le plus rapide du monde, si le temps de transfert est prohibitif, ça ne sert à rien \harritu
  \end{itemize}
\end{frame}

%****************************************************************
% memoria giltzatuta
%****************************************************************
\begin{frame}{Mémoire vérrouillée}
  \begin{itemize}[<+->]
    \item[\argi] allocation par défaut \gezi\ mémoire paginable (pouvant utiliser l'espace d'échange)
    \item[\argi] transfert \geziBikoitz\  GPU
      \begin{itemize}
        \item contrôleur DMA choisit : paginable ou verrouillée
        \item la mémoire verrouillée interdit l'utilisation du «swap»
        \item l'usage de la mémoire paginable nécessite d'abord l'allocation d'un tampon verrouillé, puis une copie vers le GPU
      \end{itemize}
  \end{itemize}
\pause
  \begin{center}
    \colorbox{white}{\includegraphics[width=0.6\linewidth]{fig/pinned_memory.eps}}
  \end{center}
\end{frame}
%****************************************************************
% memoria giltzatuta
%****************************************************************
\begin{frame}{Mémoire vérrouillée}{exemple}
  \begin{itemize}[<+->]
    \item[\argi] allocation {\tt cudaHostAlloc}, desallocation {\tt cudaFreeHost}
    \item[\argi] ou enregistrement de mémoire deja alloué par {\tt malloc} avec {\tt cudaHostRegister}
  \lstinputlisting[language=C]{code/pinned.c}
\item[\argi] on peut utiliser aussi de la mémoire associée (cudaHostAllocDefault \gezi\ cudaHostAllocMapped) pour éviter la recopie, mais la BP est moins rapide depuis les noyaux
\item[\triste] gain faible (ex sur un k40M 8.9Go/s vs 7Go/s pour 32M)
  \end{itemize}
\end{frame}
%****************************************************************
% transfert asynchrones
%****************************************************************
\begin{frame}{Transferts asynchrones}{Principe}
  \begin{itemize}[<+->]
    \item[\kontuz] les transferts classiques (ex {\tt cudaMemcpy}) sont {\bf bloquants} \harritu
\begin{center}
  \colorbox{white}{\includegraphics[width=0.6\linewidth]{fig/seq.png}}
\end{center}
    \item[\scout] utiliser des transferts {\bf asynchrones } pour recouvrir les transferts par des calculs
\begin{center}
  \colorbox{white}{\includegraphics[width=0.95\linewidth]{fig/async.png}}
\end{center}
    \item[\argi] répartir les données sur des {\bf flux} («streams») différents
    \item[\kontuz] la mémoire sur l'hôte doit être vérouillée
    \item[\pozik] le pipeline de transfert de données permet un recouvrement \\ 
      \gezi\ réduction du temps total
  \end{itemize}
\end{frame}

%****************************************************************
% transfert asynchrones : exemple
%****************************************************************
\begin{frame}{Transferts asynchrones}{Exemple}
  \begin{itemize}[<+->]
    \item[\adibi] sur d'un noyau 1D 
      \lstinputlisting[language=C]{code/asyn.c}
    \item[\faClockO] sur K40M, avec N=4Mo et 4 flux \\ \gezi\ 4.71ms (sequentiel) vs 2.67ms (asynchrone) \pozik
  \end{itemize}
\end{frame}

%****************************************************************
% Mémoires de l'accélérateur
%****************************************************************
\begin{frame}{Mémoires sur l'accélérateur}{Vue générale}
  \begin{itemize}[<+->]
    \item[\argi] un GPU abrite plusieurs types de mémoire : 
\begin{tabular}{|l|l|l|l|l|l|}
  \hline
  mémoire   & local. & Cachée  & accès     & portée   & durée \\ 
  \hline
  registre  & puce  &  N/A   & RW & thread & thread \\
  locale    & DRAM  & CC$\geqslant$2.0 & RW & thread & thread \\
  partagée  & puce  & N/A    & RW & bloc   & bloc \\
  globale   & DRAM  & CC$\geqslant$2.0  & RW & GPU et hôte &  appli. \\
  constante & DRAM  & Oui    & R  & GPU et hôte &  appli. \\
  texture   & DRAM  & Oui    & R  & GPU et hôte &  appli. \\
  \hline
\end{tabular}
  \item[\kontuz] différentes caractéristiques \gezi\ différents usages
    \begin{itemize} 
     \item mémoire locale est interne à un fils d'execution
     \item mémoire de texture : moins sensible aux accès avec pas
     \item mémoire constante permet de stocker des données constantes durant l'execution du noyau
     \item la mémoire partagée permet d'avoir un cache local pour un bloc de threads
  \end{itemize}
  \end{itemize}
\end{frame}
\begin{frame}{Mémoire locale}
  \begin{itemize}[<+->]
    \item[\scout] mémoire privée du fil d'execution hors registre (locale)
    \item[\argi] située en DRAM sur le GPU
    \item[\kontuz] facteur de contention : quantité et/ou en cache
    \item[\adibi] soit le noyau suivant compilé avec \texttt{nvcc -arch=sm\_75 --ptxas-options=-v -ptx  localMem.cu}
\lstinputlisting{code/localMem.cu}
     \item[\hand] on obtient
\lstinputlisting{code/localMem.ptx}
   \end{itemize}
\end{frame}

\begin{frame}{Mémoire constante et de texture}
  \begin{itemize}[<+->]
    \item[\argi] on peut y écrire depuis l'hôte (constante et de texture)
    \item[\scout] mémoire constante limitée à 64KB. 
    \item[\kontuz] un seul port de lecture \gezi les threads d'une même chaîne doivent accéder à la même adresse!
    \item[\scout] texture : parfois intéressants pour des accès non-contigues
   \end{itemize}
\end{frame}

%****************************************************************
% mémoire partagée : 
%****************************************************************
\begin{frame}{Mémoire partagée}
  \begin{itemize}[<+->]
    \item[\argi] mémoire partagée entre tous les threads d'un bloc
    \item[\kontuz] aux écritures concurrentes \harritu
    \item[\scout] synchronisation à l'aide de {\tt \_\_syncthreads } 
    \item[\scout] déclaration à l'aide du mot-clef {\tt \_\_shared\_\_}
    \item[\scout] allocaton statique...
  \lstinputlisting[language=C]{code/sharedStatic.c}
\item[\scout] ou dynamique
  \lstinputlisting[language=C]{code/shareDynamic.c}
   \item[\kontuz] taille limitée à 64kB
   \end{itemize}
\end{frame}

%****************************************************************
% mémoire partagée : exemple
%****************************************************************
\begin{frame}{Mémoire partagée}{Tranposition}
  \begin{itemize}[<+->]
    \item[\adibi] on considère un noyau qui transpose une matrice
  \lstinputlisting[language=C]{code/transposeNaive.c}
    \item[\triste] écriture avec un saut de longueur {\tt n.x }\gezi\ non coalescent \harritu
\begin{center}
  \colorbox{white}{\includegraphics[width=0.7\linewidth]{fig/transpose1.eps}}
\end{center}
   \end{itemize}
\end{frame}

%****************************************************************
% mémoire partagée : solution
%****************************************************************
\begin{frame}{Mémoire partagée}{solution}
  \begin{itemize}[<+->]
    \item[\argi] on utilise un cache local \gezi\ lecture coalescente \pozik
  \lstinputlisting[language=C]{code/transposeShared1.c}
\begin{center}
  \colorbox{white}{\includegraphics[width=0.60\linewidth]{fig/transpose2.eps}}
\end{center}
   \item[\faMagic] tester {\tt \_\_shared\_\_ float tile[TILE\_DIM][TILE\_DIM+1]} 
   \end{itemize}
\end{frame}

%****************************************************************
% mémoire partagée : synchronisation
%****************************************************************
\begin{frame}{Mémoire partagée}{sur l'importance de la synchonisation}
 \begin{itemize}[<+->]
   \item on veut transposer l'image suivante
\begin{center}
  \includegraphics[width=0.4\linewidth]{fig/cray.png}
\end{center}
  \item[\faClockO] image 2976x3808 sur K40M \gezi\ 0.94ms vs 0.75ms 
\end{itemize}
\pause
\begin{columns}[t]
\column{5cm}
 Sans synchronisation 
\begin{center}
  \includegraphics[width=0.3\linewidth]{fig/crayNoSync.png}
\end{center}
\column{5cm}
 Avec synchronisation
\begin{center}
  \includegraphics[width=0.3\linewidth]{fig/crayTrans.png}
\end{center}
\end{columns}
\end{frame}

%****************************************************************
% Divergence de thread
%****************************************************************
\begin{frame}{Divergence de chaînes}
 \begin{itemize}[<+->]
  \item[\kontuz] la divergence de chaîne peut degrader les performances
  \item[\adibi] soit le noyau suivant
  \lstinputlisting[language=C]{code/warpDiverge.c}
  \item[\argi] condition satisfaite par 1 thread d'une chaîne 
    \begin{itemize}
      \item[\gezi] {\bf tous} les threads de la chaîne executent cette branche
      \item[\gezi] les autres branches d'exécution sont serialisées
      \item[\gezi] masquage des résultats des threads hors branche
    \end{itemize}
  \item[\adibi] par contre le noyau suivant ne diverge pas
  \lstinputlisting[language=C]{code/warpNoDiverge.c}
  \end{itemize}
\end{frame}

%****************************************************************
% Redukzio : Monte-Carloko metodoa
%****************************************************************
\begin{frame}{Réduction}{Calcul de $\pi$ par une méthode de Monte-Carlo}
 \begin{itemize}[<+->]
   \item[\argi] On souhaite approcher $\pi$ par le calcul d'aire suivant
     \begin{columns}
       \column{5cm}
\begin{center}
  \includegraphics[width=0.5\linewidth]{fig/monteCarlo.eps}
\end{center}
       \column{5cm}
  $$A = \int_{A} dx \thicksim \frac{1}{N}\sum_{i=1}^N \mathbb{1}_{A}(x_i)$$
 où $x_i$ est pris au hasard dans $[0,1]^2$
     \end{columns}
  \item[\faBomb] méthodes dite «de Monte-Carlo» en réference à l'algorithme de Metropolis-Ulam
  \item[\triste] convergence lente en $O(\frac{1}{\sqrt{N}})$
  \item[\pozik] massivement parallélisable si on a un générateur pseudo-aléatoire parallèle (\texttt{curandGenerateUniform})
  \end{itemize}
\end{frame}


%****************************************************************
% Redukzio : Somme
%****************************************************************
\begin{frame}{Réduction}{Principe}
 \begin{itemize}[<+->]
   \item[\argi] générer en // des couples aléatoires $(x_i,y_i) \in K = [0,1]^2$
   \item[\argi] sommer en // ceux qui sont dans $A = \{ (x,y) \in K \;|\; x^2+y^2 \leqslant 1 \}$
   \item[\galde] comment calculer une somme en parallèle sur un GPU ?
   \item[\kontuz] il faut faire travailler un max de threads \harritu
   \item[\scout] par exemple, en utilisant une réduction en arbre 
  \end{itemize}
\pause
\begin{center}
  \includegraphics[width=0.6\linewidth]{fig/zuhaitz.eps}
\end{center}
\end{frame}

%****************************************************************
% Redukzio : Somme
%****************************************************************
\begin{frame}{Réduction}{2 niveaux} 
 \begin{itemize}[<+->]
   \item[\scout] On va écrire 2 noyaux, qu'on appelle en cascade
 \begin{enumerate}
   \item {\tt partialSum} qui dénombre les couples $(x_i,y_i)$ dans $A$ pour chaque bloc. 
   \item stockage du résultat en mémoire globale ({\tt partial})
   \item {\tt finalSum} calcule la somme des éléments de {\tt partial}
 \end{enumerate}
   \item[\kontuz] information commune par bloc \gezi\ mémoire partagée
   \item[\argi] schéma d'appel
     \lstinputlisting[language=C]{code/biKernels.c}
     \begin{center}  
  \includegraphics[width=0.6\linewidth]{fig/biKernels.eps}
     \end{center}  
   \item[\argi] écriture possible avec un seul noyau \gezi\ opérations {\em atomiques}
  \end{itemize}
 \end{frame}

%****************************************************************
% Redukzio : somme divergente
%****************************************************************
\begin{frame}{Réduction}{Première solution}
 \begin{enumerate}[<+->]
   \item On peut ajouter 2 cases mémoire contiguës
   \item multiplier le pas par 2
   \item et itérer...
  \end{enumerate}
\pause
\begin{center}
  \includegraphics[width=0.8\linewidth]{fig/divergent.eps}
\end{center}
\pause
\begin{itemize}
  \item[\triste] problème : le schéma est clairement divergent \harritu
  \end{itemize}
\end{frame}

%****************************************************************
% Redukzio : somme convergente
%****************************************************************
\begin{frame}{Réduction}{2$^{\mbox{ème}}$ solution}
 \begin{enumerate}[<+->]
   \item ou alors additioner avec l'element situé a {\tt blockDim.x}
   \item et diviser le pas par 2
   \item puis itérer...
  \end{enumerate}
\pause
\begin{center}
  \includegraphics[width=0.6\linewidth]{fig/convergent.eps}
\end{center}
\pause
\begin{itemize}
  \item[\pozik] le schéma ne diverge quasiment plus \harritu
  \end{itemize}
\end{frame}

%****************************************************************
% Divergence de thread
%****************************************************************
\begin{frame}{Réduction}{noyau «finalSum»}
\pause
  \lstinputlisting[language=C]{code/finalSum.c}
\pause
  \begin{itemize}[<+->]
    \item synchronisation multiple
    \item {\tt psum} : tableau partagé alloué dynamiquement de taille {\tt BLOCK\_SIZE }
  \end{itemize}
\end{frame}

\begin{frame}{Réduction}{noyau «partialSum»}
\pause
  \lstinputlisting[language=C]{code/partialSum.c}
\pause
  \begin{itemize}[<+->]
    \item chaque fil traite $\displaystyle \left\lfloor \frac{N}{\mbox{{\tt gridDim.x * blockDim.x}}}\right\rfloor $ entrées afin de gérer
    des données qui ne tiennent pas forcemment en mémoire.
  \end{itemize}
\end{frame}

\begin{frame}{Réduction}{Comparaison des performances}
  \begin{itemize}[<+->]
    \item[\faClockO] pour $N = 4*256*512$ , on compare différents GPU, avec des temps en ms
   \begin{center}
      \begin{tabular}{|l|c|c|c|}
    \hline
      GPU & 1 fil & div. & nodiv.   \\
    \hline
    k40M  & 0.074  & 0.058 & \textcolor{green}{0.045} \\
    V100  & \textcolor{red}{0.0068} & 0.011 & 0.0072 \\
    T4    & 0.0302 & 0.0407& \textcolor{green}{0.0274} \\
    \hline
    \end{tabular}
    \end{center}
  \end{itemize}
\end{frame}
%****************************************************************
% hirurgarren partea : denetarik
%****************************************************************
\begin{frame}
  \begin{center}
    {\Huge $3^{\mbox{ème}}$ partie : Divers }
  \end{center}
\end{frame}

%****************************************************************
% gpu-ri buruzko historio motz bat
%****************************************************************
\begin{frame}{Une brève histoire des GPUs}{Les premiers âges}
  \begin{columns}[t]
    \column{7cm}
    \begin{itemize}[<+->]
      \item bonne synthèse sur \href{https://www.techspot.com/article/650-history-of-the-gpu/}{\beamergotobutton{Techspot}}
      \item premiers coprocesseurs graphiques évidemment qu'en 2D
        \begin{itemize}
          \item 1976 : RCA Pixie (résolution 62x128)
          \item 1977 : Adaptateur d'interface de Télevision TIA 1A (Atari 2600)
          \item 1981 : Motorola MC6845 (IBM PC, Apple II)
        \end{itemize}
    \end{itemize}
    \column{5cm}
    \begin{figure}[htbp]
  \includegraphics[width=0.8\linewidth]{fig/appleII.jpg}
    \caption{\tiny Apple IIe : 560x192 en monochrome, 15 couleurs en 140x192 !}
    \end{figure}
  \end{columns}
\end{frame}


%****************************************************************
% souvenirs, souvenirs
%****************************************************************
\begin{frame}{Souvenirs, souvenirs}{Lode Runner sur Apple IIe}
  \begin{center}
  \includegraphics[width=0.8\linewidth]{fig/lode_runner.png}
  \end{center}
\end{frame}

%****************************************************************
% gpu-ri buruzko historio motz bat
%****************************************************************
\begin{frame}{Une brève histoire des GPUs}{les premiers âges}
  \begin{columns}[t]
    \column{7cm}
    \begin{itemize}[<+->]
     \item 1983: Intel iSBX 275 Video Graphics 
    Controller Multimode Board
    \begin{itemize}
      \item 256x256, 8 colors
  \item 512x512 monochrome
  \item Lignes, rectangles, cercles...
  \item zoom \& défilement matériels
  \item 32KB, 1000\$ \harritu
  \item simulateurs de vol (Armée)
    \end{itemize} 
    \item 1987: ATI EGA
      \begin{itemize}
        \item 650x350, 16 couleurs
        \item 512x512 monochrome
        \item 256KB de DRAM
        \item 399\$ \pozik
        \item EGA Wonder 800
        \begin{itemize}
          \item  800x600 VGA
          \item  449\$
        \end{itemize} 
      \end{itemize} 
   \end{itemize} 
    \column{5cm}
    \begin{figure}[htbp]
  \includegraphics[width=0.8\linewidth]{fig/sbx2.png}
      \caption{\tiny iSBX 275}
    \end{figure}
\begin{figure}[htbp]
  \includegraphics[width=0.8\linewidth]{fig/ati_ega.png}
      \caption{\tiny ATI EGA Wonder 800}
    \end{figure}
  \end{columns}
\end{frame}

%****************************************************************
% gpu-ri buruzko historio motz bat
%****************************************************************
\begin{frame}{Une brève histoire des GPUs}{les premiers âges}
  \begin{columns}[t]
    \column{7cm}
    \begin{itemize}[<+->]
      \item 1992 : SGI publie OpenGL 1.0 
        \begin{itemize}
          \item Interface de Programmation Applicative (IPA) pour 
            la 2D et 3D.
         \item initialement prévu pour Uni
         \item vite adopté pour les jeux 3D
         \end{itemize}
      \item 1992: Wolfenstein 3D (Id Software)
        \begin{itemize}
          \item un des premiers FPS (jeux de tir en vue subjective)
            \href{https://classicreload.com/wolfenstein-3d.html}{\beamergotobutton{Jouer}}
         \end{itemize}
      \item 1993: naissance de Nvidia
      \item 1995: Microsoft promeut son IPA Direct3D 
    \end{itemize} 
    \column{5cm}
\begin{figure}[htbp]
  \includegraphics[width=0.7\linewidth]{fig/opengl.png}
 \end{figure}
\begin{figure}[htbp]
  \includegraphics[width=0.8\linewidth]{fig/wolf2.png}
    \end{figure}
  \end{columns}
\end{frame}

%****************************************************************
% gpu-ri buruzko historio motz bat
%****************************************************************
\begin{frame}{Une brève histoire des GPUs}{ou comment la 3dfx Voodoo change la donne}
  \begin{columns}[t]
    \column{7cm}
    \begin{itemize}[<+->]
      \item 1995 : IPA Glide publié par 3dfx interactive
        \begin{itemize}
         \item sous-ensemble de OpenlGL 1.1
         \item placage de texture
         \end{itemize}
      \item 1995 : Nvidia NV1 : premiere puce integrant
        \begin{itemize}
          \item rendu 3D
          \item accélération vidéo
         \end{itemize}
      \item 1996 : 3dfx voodo Graphics
        \begin{itemize}
          \item uniquement 3D, IPA Glide
          \item application phare : Quake (ID software)
        \end{itemize} 
    \end{itemize} 
    \column{5cm}
\begin{figure}[htbp]
  \includegraphics[width=0.7\linewidth]{fig/3dfx.jpg}
 \end{figure}
\begin{figure}[htbp]
  \includegraphics[width=0.8\linewidth]{fig/quake_3fx.png}
    \end{figure}
  \end{columns}
\end{frame}

%****************************************************************
% gpu-ri buruzko historio motz bat
%****************************************************************
\begin{frame}{Une brève histoire des GPUs}{ATI contre NVIDIA}
  \begin{columns}[t]
    \column{7cm}
    \begin{itemize}[<+->]
      \item 1999 : Nvidia GeForce 256
        \begin{itemize}
         \item Premier GPU
         \item technologie materielle {\em Transform and Lighting}\/ (T\&L)
         \item mémoire 32-64 Mo
         \item Fréquence GPU : 120 Mhz
         \item Fréquence Mémoire : 166-300Mhz
         \end{itemize}
      \item 2000 : ATI Radeon 7xxx
        \begin{itemize}
          \item techno T\&L
          \item mémoire 32-64Mo
          \item Fréquence GPU : 180-260Mhz
          \item Fréquence Mémoire : 360-460Mhz
          \item plusieurs cœurs de rendus
         \end{itemize}
    \end{itemize} 
    \column{5cm}
\begin{figure}[htbp]
  \includegraphics[width=0.7\linewidth]{fig/geforce256.jpg}
      \caption{\tiny Nvidia  GeForce 256}
 \end{figure}
\begin{figure}[htbp]
  \includegraphics[width=0.8\linewidth]{fig/radeon7500.jpg}
      \caption{\tiny ATI Radeon 7500}
    \end{figure}
  \end{columns}
\end{frame}

%****************************************************************
% gpu-ri buruzko historio motz bat
%****************************************************************
\begin{frame}{Une brève histoire des GPUs}{l'ère des GPGPUs}
  \begin{columns}[t]
    \column{6cm}
    \begin{itemize}[<+->]
      \item 2001 : Nvidia GeForce 3 (NV20)
        \begin{itemize}
          \item unités programmables (nuanceurs)
         \end{itemize}
       \item les GPUs deviennent des accélérateurs de calcul génériques (GPGPU)
        \begin{itemize}
          \item les textures peuvent embarquer n'importe quelle donnée
          \item les {\em nuanceurs}\/ (shaders) peuvent pratiquement faire
            n'importe quel calcul
          \item OpenGL peut dorenavant être utiliser pour faire du calcul scientifique
         \end{itemize}
    \end{itemize} 
    \column{6cm}
\begin{figure}[htbp]
  \includegraphics[width=0.8\linewidth]{fig/geforce3.jpg}
      \caption{\tiny Nvidia GeForce 3}
 \end{figure}
  \end{columns}
\end{frame}

%****************************************************************
% gpu-ri buruzko historio motz bat
%****************************************************************
\begin{frame}{Une brève histoire des GPUs}{les accélérateurs GPU}
  \begin{columns}[t]
    \column{6cm}
    \begin{itemize}[<+->]
      \item 2007 : Nvidia anticipe le marché possible et publie l'IPA CUDA
         Compute Unified Device Architecture)
      \item Nvidia lance aussi les accélérateurs Tesla
        \begin{itemize}
          \item sans sortie vidéo \harritu
          \item unités double précision
          \item code de correction d'erreurs (ECC mode) pour augmenter la robustesse
         \end{itemize}
       \item AMD (ex. ATI) publie
        \begin{itemize}
          \item l'IPA «Close to the Metal»
          \item le SDK «Stream»
        \end{itemize}
    \end{itemize} 
    \column{5cm}
\pause
\begin{figure}[htbp]
  \includegraphics[width=0.7\linewidth]{fig/C1060.jpg}
      \caption{\tiny Tesla C1060}
 \end{figure}
\begin{figure}[htbp]
  \includegraphics[height=4cm, width=0.9\linewidth]{fig/nb_coeurs_gpu.eps}
 \end{figure}
  \end{columns}
\end{frame}

%****************************************************************
% gpu-ri buruzko historio motz bat
%****************************************************************
\begin{frame}{Une brève histoire des GPUs}{les dernières améliorations}
  \begin{columns}[t]
    \column{7cm}
    \begin{itemize}[<+->]
      \item Pascal :
        \begin{itemize}
          \item bus à haute-vitesse NVLink entre GPU et Hôte (jusqu'à 20Go/s)
          \item prise en charge de la demi-précision (16 bits)
          \item mémoire unifiée
         \end{itemize}
       \item Volta : 
        \begin{itemize}
          \item NVlink débit 25 Go/s
          \item cœurs Tenseurs : 
        \begin{itemize}
          \item opération FMA sur des matrices 4x4
          \item $D = A \times B + C$ \gezi réseaux de neurones
         \end{itemize}
        \end{itemize}
       \item Turing :
         \begin{itemize}
          \item mémoire GDDR6 : 5001Mhz!
          \item meilleure prise en charge des cœurs tenseurs
         \end{itemize}
    \end{itemize} 
\pause
    \column{4cm}
    \begin{figure}[htbp]
  \includegraphics[width=0.7\linewidth]{fig/tensorCore.png}
 \end{figure}
\begin{figure}[htbp]
  \includegraphics[width=0.9\linewidth]{fig/flux2.png}
 \end{figure}
  \end{columns}
\end{frame}

%****************************************************************
% liburutegiak
%****************************************************************
\begin{frame}{Interfaces de programmation applicatives}
  \begin{itemize}[<+->]
    \item langages (autre que C/C++) pour interfacer CUDA
  \begin{itemize}
    \item Fortran (compilateur PGI)
    \item Python, Julia et Matlab (avec cadriciels, Pytorch, flux.jl)
  \end{itemize} 
    \item bibliothèques optimisées pour CUDA
  \begin{itemize}
    \item Cublas et CuLA (algébre linéaire dense)
    \item Curand (génération de nombres aléatoires)
    \item CuFFT (transformées de fourier discrètes)
    \item CuDNN (apprentissage automatique)
    \item Cusparse (algèbre linéaire creuse)
    \item Thrust (CUDA à la mode STL)
    \item Magma (algébre linéaire sur archis hétérogènes)
  \end{itemize} 
    \item Standard OpenCL
  \begin{itemize}
    \item plus générique que CUDA 
    \item prise en charge des archi NVidia
    \item mais aussi d'AMD 
  \end{itemize} 
    \item ACC / OpenMP
  \end{itemize} 
\end{frame}

%****************************************************************
% Apaimenak
%****************************************************************
\begin{frame}{Références}
\begin{itemize}[<+->]
  \item[\liburu] Cuda Fortran for Scientists and Engineers, G. Ruetsch, M. Fatica
  \item[\Pdf] Programming GPU Accelerators with OpenCL, R. Namyst, P.-A. Wacrenier \href{https://raymond-namyst.emi.u-bordeaux.fr/ens/pap/PAP-GPU.pdf}{\beamergotobutton{pdf}}
  \item[\Pdf] Performance Optimization Strategies For GPU-Accelerated Applications D. Goodwin \href{https://on-demand.gputechconf.com/gtc/2013/presentations/S3046-Performance-Optimization-Strategies-for-GPU-Accelerated-Apps.pdf}{\beamergotobutton{pdf}}
  \item[\faFilePowerpointO] CUDA Basics, S. Vialle \href{http://www.metz.supelec.fr/metz/personnel/vialle/course/PPS-5A-GPGPU/notes-de-cours-specifiques/PPS-GPU-02-CUDA-Basics-2spp.pdf}{\beamergotobutton{pdf}}
  \item[\Pdf] Understanding Latency Hiding on GPUs, V. Volkov \href{http://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-143.pdf}{\beamergotobutton{pdf}}
  \item[\Pdf] The Monte Carlo Method, N. Metropolis, S. Ulam,  Journal of the American Statistical Association Volume 44, 1949 
    \href{http://www.tandfonline.com/doi/abs/10.1080/01621459.1949.10483310}{\beamergotobutton{pdf}}
\end{itemize}
\end{frame}
\end{document}
